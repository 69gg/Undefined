import asyncio
import base64
import logging
import re
import time
from uuid import uuid4
from datetime import datetime
from typing import Any, Awaitable, Callable, Optional
from pathlib import Path

from Undefined.config import Config
from Undefined.faq import FAQStorage, extract_faq_title
from Undefined.onebot import (
    OneBotClient,
    get_message_content,
    get_message_sender_id,
    parse_message_time,
)
from Undefined.utils.sender import MessageSender
from Undefined.services.commands.context import CommandContext
from Undefined.services.commands.registry import CommandMeta, CommandRegistry
from Undefined.services.security import SecurityService
from Undefined.token_usage_storage import TokenUsageStorage

# å°è¯•å¯¼å…¥ matplotlib
plt: Any
try:
    import matplotlib.pyplot as plt

    _MATPLOTLIB_AVAILABLE = True
except ImportError:
    plt = None
    _MATPLOTLIB_AVAILABLE = False

logger = logging.getLogger(__name__)


_STATS_DEFAULT_DAYS = 7
_STATS_MIN_DAYS = 1
_STATS_MAX_DAYS = 365
_STATS_MODEL_TOP_N = 8
_STATS_CALL_TYPE_TOP_N = 12
_STATS_DATA_SUMMARY_MAX_CHARS = 12000
_STATS_AI_FLAGS = {"--ai", "-a"}
_STATS_TIME_RANGE_RE = re.compile(r"^\d+[dwm]?$", re.IGNORECASE)


class _PrivateCommandSenderProxy:
    """å°†å‘½ä»¤å¤„ç†å™¨é‡Œçš„ send_group_message ä»£ç†åˆ°ç§èŠå‘é€ã€‚"""

    def __init__(
        self,
        user_id: int,
        send_private_message: Callable[[int, str], Awaitable[None]],
    ) -> None:
        self._user_id = user_id
        self._send_private_message = send_private_message

    async def send_group_message(
        self,
        group_id: int,
        message: str,
        mark_sent: bool = False,
    ) -> None:
        _ = group_id, mark_sent
        await self._send_private_message(self._user_id, message)

    async def send_private_message(
        self,
        user_id: int,
        message: str,
        auto_history: bool = True,
        *,
        mark_sent: bool = True,
    ) -> None:
        _ = user_id, auto_history, mark_sent
        await self._send_private_message(self._user_id, message)


class CommandDispatcher:
    """å‘½ä»¤åˆ†å‘å¤„ç†å™¨ï¼Œè´Ÿè´£è§£æå’Œæ‰§è¡Œæ–œæ å‘½ä»¤"""

    def __init__(
        self,
        config: Config,
        sender: MessageSender,
        ai: Any,  # AIClient
        faq_storage: FAQStorage,
        onebot: OneBotClient,
        security: SecurityService,
        queue_manager: Any = None,
        rate_limiter: Any = None,
    ) -> None:
        """åˆå§‹åŒ–å‘½ä»¤åˆ†å‘å™¨

        å‚æ•°:
            config: å…¨å±€é…ç½®å®ä¾‹
            sender: æ¶ˆæ¯å‘é€åŠ©æ‰‹
            ai: AI å®¢æˆ·ç«¯(ç”¨äºå½’çº³å’Œæ ‡é¢˜ç”Ÿæˆ)
            faq_storage: FAQ å­˜å‚¨ç®¡ç†å™¨
            onebot: OneBot HTTP API å®¢æˆ·ç«¯
            security: å®‰å…¨å®¡è®¡ä¸é™æµæœåŠ¡
            queue_manager: AI è¯·æ±‚é˜Ÿåˆ—ç®¡ç†å™¨
            rate_limiter: é€Ÿç‡é™åˆ¶å™¨
        """
        self.config = config
        self.sender = sender
        self.ai = ai
        self.faq_storage = faq_storage
        self.onebot = onebot
        self.security = security
        self.queue_manager = queue_manager
        self.rate_limiter = rate_limiter
        self._token_usage_storage = TokenUsageStorage()
        # å­˜å‚¨ stats åˆ†æç»“æœï¼Œç”¨äºé˜Ÿåˆ—å›è°ƒ
        self._stats_analysis_results: dict[str, str] = {}
        self._stats_analysis_events: dict[str, asyncio.Event] = {}

        # åŠ è½½æ‰€æœ‰å‘½ä»¤å®ç° (ç‹¬ç«‹æ’ä»¶å½¢å¼å­˜æ”¾åœ¨ skills/commands ç›®å½•ä¸‹)
        commands_dir = Path(__file__).parent.parent / "skills" / "commands"
        self.command_registry = CommandRegistry(commands_dir)
        self.command_registry.load_commands()
        logger.info("[å‘½ä»¤] å‘½ä»¤ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ: dir=%s", commands_dir)

    def parse_command(self, text: str) -> Optional[dict[str, Any]]:
        """è§£ææ–œæ å‘½ä»¤å­—ç¬¦ä¸²

        å‚æ•°:
            text: åŸå§‹æ–‡æœ¬å†…å®¹

        è¿”å›:
            åŒ…å«å‘½ä»¤å(name)å’Œå‚æ•°åˆ—è¡¨(args)çš„å­—å…¸ï¼Œè§£æå¤±è´¥åˆ™è¿”å› None
        """
        clean_text = re.sub(r"\[@\s*\d+(?:\(.*?\))?\]", "", text).strip()
        match = re.match(r"/(\w+)\s*(.*)", clean_text)
        if not match:
            return None

        cmd_name = match.group(1).lower()
        args_str = match.group(2).strip()

        logger.debug(
            "[å‘½ä»¤] è§£æå‘½ä»¤: text_len=%s cmd=%s args=%s",
            len(text),
            cmd_name,
            args_str,
        )
        return {
            "name": cmd_name,
            "args": args_str.split() if args_str else [],
        }

    def _parse_time_range(self, time_str: str) -> int:
        """è§£ææ—¶é—´èŒƒå›´å­—ç¬¦ä¸²ï¼Œè¿”å›å¤©æ•°

        å‚æ•°:
            time_str: æ—¶é—´èŒƒå›´å­—ç¬¦ä¸²ï¼ˆå¦‚ "7d", "1w", "30d"ï¼‰

        è¿”å›:
            å¤©æ•°
        """
        if not time_str:
            return _STATS_DEFAULT_DAYS

        def _clamp_days(value: int) -> int:
            if value < _STATS_MIN_DAYS:
                return _STATS_DEFAULT_DAYS
            if value > _STATS_MAX_DAYS:
                return _STATS_MAX_DAYS
            return value

        time_str = time_str.lower().strip()

        # è§£æå¿«æ·æ ¼å¼
        if time_str.endswith("d"):
            try:
                return _clamp_days(int(time_str[:-1]))
            except ValueError:
                return _STATS_DEFAULT_DAYS
        elif time_str.endswith("w"):
            try:
                return _clamp_days(int(time_str[:-1]) * 7)
            except ValueError:
                return _STATS_DEFAULT_DAYS
        elif time_str.endswith("m"):
            try:
                return _clamp_days(int(time_str[:-1]) * 30)
            except ValueError:
                return _STATS_DEFAULT_DAYS

        # å°è¯•ç›´æ¥è§£æä¸ºæ•°å­—ï¼ˆé»˜è®¤ä¸ºå¤©ï¼‰
        try:
            return _clamp_days(int(time_str))
        except ValueError:
            return _STATS_DEFAULT_DAYS

    def _parse_stats_options(self, args: list[str]) -> tuple[int, bool]:
        """è§£æ /stats å‚æ•°ï¼šæ—¶é—´èŒƒå›´ + AI åˆ†æå¼€å…³ã€‚"""
        days = _STATS_DEFAULT_DAYS
        enable_ai_analysis = False
        picked_days = False

        for raw in args:
            token = str(raw or "").strip()
            if not token:
                continue
            lower = token.lower()
            if lower in _STATS_AI_FLAGS:
                enable_ai_analysis = True
                continue
            if not picked_days and _STATS_TIME_RANGE_RE.match(lower):
                days = self._parse_time_range(lower)
                picked_days = True

        return days, enable_ai_analysis

    async def _handle_stats(
        self, group_id: int, sender_id: int, args: list[str]
    ) -> None:
        """å¤„ç† /stats å‘½ä»¤ï¼Œç”Ÿæˆ token ä½¿ç”¨ç»Ÿè®¡å›¾è¡¨ï¼ˆå¯é€‰ AI åˆ†æï¼‰"""
        # 1. åŸºç¡€ç¯å¢ƒä¸å‚æ•°æ£€æŸ¥
        if not _MATPLOTLIB_AVAILABLE:
            await self.sender.send_group_message(
                group_id, "âŒ ç¼ºå°‘å¿…è¦çš„åº“ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨ã€‚è¯·å®‰è£… matplotlibã€‚"
            )
            return

        days, enable_ai_analysis = self._parse_stats_options(args)

        try:
            # 2. è·å–å¹¶éªŒè¯æ•°æ®
            summary = await self._token_usage_storage.get_summary(days=days)
            if summary["total_calls"] == 0:
                await self.sender.send_group_message(
                    group_id, f"ğŸ“Š æœ€è¿‘ {days} å¤©å†…æ—  Token ä½¿ç”¨è®°å½•ã€‚"
                )
                return

            # 3. ç”Ÿæˆå›¾è¡¨æ–‡ä»¶
            from Undefined.utils.paths import RENDER_CACHE_DIR, ensure_dir

            img_dir = ensure_dir(RENDER_CACHE_DIR)
            await self._generate_line_chart(summary, img_dir, days)
            await self._generate_bar_chart(summary, img_dir)
            await self._generate_pie_chart(summary, img_dir)
            await self._generate_stats_table(summary, img_dir)

            # 4. æŒ‰å‚æ•°æŠ•é€’ AI åˆ†æè¯·æ±‚åˆ°é˜Ÿåˆ—ï¼ˆé»˜è®¤å…³é—­ï¼‰
            ai_analysis = ""
            if enable_ai_analysis:
                ai_analysis = await self._run_stats_ai_analysis(
                    scope="group",
                    scope_id=group_id,
                    sender_id=sender_id,
                    summary=summary,
                    days=days,
                )

            # 5. æ„å»ºå¹¶å‘é€åˆå¹¶è½¬å‘æ¶ˆæ¯ï¼ˆåŒ…å« AI åˆ†æï¼‰
            forward_messages = self._build_stats_forward_nodes(
                summary, img_dir, days, ai_analysis
            )
            await self.onebot.send_forward_msg(group_id, forward_messages)

            from Undefined.utils.cache import cleanup_cache_dir

            cleanup_cache_dir(RENDER_CACHE_DIR)

        except Exception as e:
            error_id = uuid4().hex[:8]
            logger.exception(
                "[Stats] ç”Ÿæˆç»Ÿè®¡å›¾è¡¨å¤±è´¥: error_id=%s err=%s", error_id, e
            )
            await self.sender.send_group_message(
                group_id,
                f"âŒ ç”Ÿæˆç»Ÿè®¡å›¾è¡¨å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ï¼ˆé”™è¯¯ç : {error_id}ï¼‰",
            )

    async def _handle_stats_private(
        self,
        user_id: int,
        sender_id: int,
        args: list[str],
        send_message: Callable[[str], Awaitable[None]] | None = None,
        *,
        is_webui_session: bool = False,
    ) -> None:
        """å¤„ç†ç§èŠ /statsï¼ˆå« WebUI è™šæ‹Ÿç§èŠé€‚é…ï¼‰ã€‚"""

        async def _send_private(message: str) -> None:
            if send_message is not None:
                await send_message(message)
            else:
                await self.sender.send_private_message(user_id, message)

        days, enable_ai_analysis = self._parse_stats_options(args)
        try:
            summary = await self._token_usage_storage.get_summary(days=days)
            if summary["total_calls"] == 0:
                await _send_private(f"ğŸ“Š æœ€è¿‘ {days} å¤©å†…æ—  Token ä½¿ç”¨è®°å½•ã€‚")
                return

            ai_analysis = ""
            if enable_ai_analysis:
                ai_analysis = await self._run_stats_ai_analysis(
                    scope="private",
                    scope_id=0,
                    sender_id=sender_id,
                    summary=summary,
                    days=days,
                )

            if not _MATPLOTLIB_AVAILABLE:
                message = "âŒ ç¼ºå°‘å¿…è¦çš„åº“ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨ã€‚è¯·å®‰è£… matplotlibã€‚"
                if is_webui_session:
                    message += "\n\n" + self._build_stats_summary_text(summary)
                    if ai_analysis:
                        message += f"\n\nğŸ¤– AI æ™ºèƒ½åˆ†æ\n{ai_analysis}"
                await _send_private(message)
                return

            from Undefined.utils.paths import RENDER_CACHE_DIR, ensure_dir
            from Undefined.utils.cache import cleanup_cache_dir

            img_dir = ensure_dir(RENDER_CACHE_DIR)
            await self._generate_line_chart(summary, img_dir, days)
            await self._generate_bar_chart(summary, img_dir)
            await self._generate_pie_chart(summary, img_dir)
            await self._generate_stats_table(summary, img_dir)

            await _send_private(f"ğŸ“Š æœ€è¿‘ {days} å¤©çš„ Token ä½¿ç”¨ç»Ÿè®¡ï¼š")
            for img_name in ["line_chart", "bar_chart", "pie_chart", "table"]:
                img_path = img_dir / f"stats_{img_name}.png"
                if img_path.exists():
                    message = await self._build_private_stats_image_message(
                        img_path,
                        inline_base64=is_webui_session,
                    )
                    await _send_private(message)

            await _send_private(self._build_stats_summary_text(summary))
            if ai_analysis:
                await _send_private(f"ğŸ¤– AI æ™ºèƒ½åˆ†æ\n{ai_analysis}")

            cleanup_cache_dir(RENDER_CACHE_DIR)
        except Exception as e:
            error_id = uuid4().hex[:8]
            logger.exception(
                "[Stats] ç§èŠç»Ÿè®¡ç”Ÿæˆå¤±è´¥: error_id=%s user=%s err=%s",
                error_id,
                user_id,
                e,
            )
            await _send_private(
                f"âŒ ç”Ÿæˆç»Ÿè®¡å›¾è¡¨å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ï¼ˆé”™è¯¯ç : {error_id}ï¼‰"
            )

    async def _build_private_stats_image_message(
        self,
        image_path: Path,
        *,
        inline_base64: bool,
    ) -> str:
        file_uri = image_path.absolute().as_uri()
        if not inline_base64:
            return f"[CQ:image,file={file_uri}]"

        try:
            encoded = await asyncio.to_thread(
                lambda: base64.b64encode(image_path.read_bytes()).decode("ascii")
            )
        except Exception as exc:
            logger.warning(
                "[Stats] å›¾åƒ base64 ç¼–ç å¤±è´¥ï¼Œå›é€€æ–‡ä»¶è·¯å¾„: path=%s err=%s",
                file_uri,
                exc,
            )
            return f"[CQ:image,file={file_uri}]"

        return f"[CQ:image,file=base64://{encoded}]"

    async def _run_stats_ai_analysis(
        self,
        *,
        scope: str,
        scope_id: int,
        sender_id: int,
        summary: dict[str, Any],
        days: int,
    ) -> str:
        if not self.queue_manager:
            return ""

        data_summary = self._build_data_summary(summary, days)
        request_id = uuid4().hex
        analysis_event = asyncio.Event()
        self._stats_analysis_events[request_id] = analysis_event
        request_data = {
            "type": "stats_analysis",
            "group_id": scope_id,
            "request_id": request_id,
            "sender_id": sender_id,
            "data_summary": data_summary,
            "summary": summary,
            "days": days,
            "scope": scope,
        }
        await self.queue_manager.add_group_mention_request(
            request_data, model_name=self.config.chat_model.model_name
        )
        logger.info("[Stats] å·²æŠ•é€’ AI åˆ†æè¯·æ±‚: scope=%s target=%s", scope, scope_id)

        try:
            await asyncio.wait_for(analysis_event.wait(), timeout=480.0)
            ai_analysis = self._stats_analysis_results.pop(request_id, "")
            logger.info(
                "[Stats] å·²è·å– AI åˆ†æç»“æœ: scope=%s len=%s", scope, len(ai_analysis)
            )
            return ai_analysis
        except asyncio.TimeoutError:
            logger.warning("[Stats] AI åˆ†æè¶…æ—¶: scope=%s target=%s", scope, scope_id)
            return "AI åˆ†æè¶…æ—¶ï¼Œå·²å…ˆå‘é€å›¾è¡¨ä¸æ±‡æ€»æ•°æ®ã€‚"
        finally:
            self._stats_analysis_events.pop(request_id, None)
            self._stats_analysis_results.pop(request_id, None)

    def _build_data_summary(self, summary: dict[str, Any], days: int) -> str:
        """æ„å»ºç”¨äº AI åˆ†æçš„ç»Ÿè®¡æ•°æ®æ‘˜è¦"""
        lines = []
        lines.append("ğŸ“Š Token ä½¿ç”¨ç»¼åˆåˆ†ææ•°æ®ï¼š")
        lines.append("")

        # æ•´ä½“æ¦‚å†µ
        lines.append("ã€æ•´ä½“æ¦‚å†µã€‘")
        lines.append(f"ç»Ÿè®¡å‘¨æœŸ: {days} å¤©")
        lines.append(f"æ€»è°ƒç”¨æ¬¡æ•°: {summary['total_calls']}")
        lines.append(f"æ€» Token æ¶ˆè€—: {summary['total_tokens']:,}")
        lines.append(f"å¹³å‡å“åº”æ—¶é—´: {summary['avg_duration']:.2f}s")
        lines.append(f"æ¶‰åŠæ¨¡å‹æ•°: {len(summary['models'])}")
        lines.append("")

        # æ—¶é—´ç»´åº¦
        daily_stats = summary.get("daily_stats", {})
        if daily_stats:
            dates = sorted(daily_stats.keys())
            total_daily_calls = sum(daily_stats[d]["calls"] for d in dates)
            total_daily_tokens = sum(daily_stats[d]["tokens"] for d in dates)
            avg_daily_calls = total_daily_calls / len(dates) if dates else 0
            avg_daily_tokens = total_daily_tokens / len(dates) if dates else 0

            # æ‰¾å‡ºé«˜å³°æ—¥
            peak_day = (
                max(dates, key=lambda d: daily_stats[d]["tokens"]) if dates else ""
            )
            peak_day_tokens = daily_stats[peak_day]["tokens"] if peak_day else 0

            lines.append("ã€æ—¶é—´ç»´åº¦ã€‘")
            lines.append(f"ç»Ÿè®¡å¤©æ•°: {len(dates)} å¤©")
            lines.append(f"æ¯æ—¥å¹³å‡è°ƒç”¨: {avg_daily_calls:.1f} æ¬¡")
            lines.append(f"æ¯æ—¥å¹³å‡ Token: {avg_daily_tokens:,.0f} ä¸ª")
            lines.append(f"é«˜å³°æ—¥æœŸ: {peak_day} ({peak_day_tokens:,} tokens)")
            lines.append("")

        # æ¨¡å‹ç»´åº¦
        models = summary.get("models", {})
        if models:
            lines.append("ã€æ¨¡å‹ç»´åº¦ã€‘")
            total_tokens_all = summary["total_tokens"]
            sorted_models = sorted(
                models.items(), key=lambda x: x[1]["tokens"], reverse=True
            )
            for model_name, model_data in sorted_models[:_STATS_MODEL_TOP_N]:
                calls = model_data["calls"]
                tokens = model_data["tokens"]
                prompt_tokens = model_data["prompt_tokens"]
                completion_tokens = model_data["completion_tokens"]
                token_pct = (
                    (tokens / total_tokens_all * 100) if total_tokens_all > 0 else 0
                )
                avg_per_call = tokens / calls if calls > 0 else 0
                io_ratio = completion_tokens / prompt_tokens if prompt_tokens > 0 else 0

                lines.append(f"æ¨¡å‹: {model_name}")
                lines.append(
                    f"  - è°ƒç”¨æ¬¡æ•°: {calls} ({calls / summary['total_calls'] * 100:.1f}%)"
                )
                lines.append(f"  - Token æ¶ˆè€—: {tokens:,} ({token_pct:.1f}%)")
                lines.append(f"  - å¹³å‡æ¯æ¬¡è°ƒç”¨: {avg_per_call:.0f} tokens")
                lines.append(
                    f"  - è¾“å…¥: {prompt_tokens:,} / è¾“å‡º: {completion_tokens:,}"
                )
                lines.append(f"  - è¾“å…¥/è¾“å‡ºæ¯”: 1:{io_ratio:.2f}")
                lines.append("")

            if len(sorted_models) > _STATS_MODEL_TOP_N:
                others = sorted_models[_STATS_MODEL_TOP_N:]
                others_calls = sum(int(item[1].get("calls", 0)) for item in others)
                others_tokens = sum(int(item[1].get("tokens", 0)) for item in others)
                others_pct = (
                    (others_tokens / total_tokens_all * 100)
                    if total_tokens_all > 0
                    else 0.0
                )
                lines.append(
                    f"å…¶ä½™ {len(others)} ä¸ªæ¨¡å‹åˆè®¡: è°ƒç”¨ {others_calls} æ¬¡, Token {others_tokens:,} ({others_pct:.1f}%)"
                )
                lines.append("")

        # è°ƒç”¨ç±»å‹ç»´åº¦
        call_types = summary.get("call_types", {})
        if call_types:
            lines.append("ã€è°ƒç”¨ç±»å‹ç»´åº¦ã€‘")
            sorted_types = sorted(
                call_types.items(), key=lambda item: int(item[1]), reverse=True
            )
            total_calls = max(1, int(summary.get("total_calls", 0)))
            for call_type, count in sorted_types[:_STATS_CALL_TYPE_TOP_N]:
                ratio = int(count) / total_calls * 100
                lines.append(f"- {call_type}: {count} æ¬¡ ({ratio:.1f}%)")
            if len(sorted_types) > _STATS_CALL_TYPE_TOP_N:
                rest_count = sum(
                    int(item[1]) for item in sorted_types[_STATS_CALL_TYPE_TOP_N:]
                )
                ratio = rest_count / total_calls * 100
                lines.append(
                    f"- å…¶ä»– {len(sorted_types) - _STATS_CALL_TYPE_TOP_N} ç±»: {rest_count} æ¬¡ ({ratio:.1f}%)"
                )
            lines.append("")

        # æ•ˆç‡æŒ‡æ ‡
        prompt_tokens = summary.get("prompt_tokens", 0)
        completion_tokens = summary.get("completion_tokens", 0)
        total_tokens = summary.get("total_tokens", 0)
        input_ratio = (prompt_tokens / total_tokens * 100) if total_tokens > 0 else 0
        output_ratio = (
            (completion_tokens / total_tokens * 100) if total_tokens > 0 else 0
        )
        output_per_input = completion_tokens / prompt_tokens if prompt_tokens > 0 else 0

        lines.append("ã€æ•ˆç‡æŒ‡æ ‡ã€‘")
        lines.append(f"è¾“å…¥ Token: {prompt_tokens:,} ({input_ratio:.1f}%)")
        lines.append(f"è¾“å‡º Token: {completion_tokens:,} ({output_ratio:.1f}%)")
        lines.append(f"è¾“å…¥/è¾“å‡ºæ¯”: 1:{output_per_input:.2f}")
        lines.append("")

        # è¶‹åŠ¿åˆ†æ
        if daily_stats and len(daily_stats) > 1:
            lines.append("ã€è¶‹åŠ¿åˆ†æã€‘")
            dates = sorted(daily_stats.keys())
            first_day_tokens = daily_stats[dates[0]]["tokens"]
            last_day_tokens = daily_stats[dates[-1]]["tokens"]
            trend_change = (
                ((last_day_tokens - first_day_tokens) / first_day_tokens * 100)
                if first_day_tokens > 0
                else 0
            )
            trend_desc = "å¢é•¿" if trend_change > 0 else "ä¸‹é™"
            lines.append(
                f"æ€»ä½“è¶‹åŠ¿: {trend_desc} {abs(trend_change):.1f}% (ä»é¦–æ—¥åˆ°æœ«æ—¥)"
            )
            lines.append("")

        summary_text = "\n".join(lines)
        if len(summary_text) > _STATS_DATA_SUMMARY_MAX_CHARS:
            trimmed = summary_text[: _STATS_DATA_SUMMARY_MAX_CHARS - 80].rstrip()
            summary_text = (
                f"{trimmed}\n\n[æ•°æ®æ‘˜è¦å·²æˆªæ–­ï¼Œæ€»é•¿åº¦ {len(summary_text)} å­—ç¬¦ï¼Œ"
                f"ä»…ä¿ç•™å‰ {_STATS_DATA_SUMMARY_MAX_CHARS} å­—ç¬¦]"
            )
            logger.info(
                "[Stats] æ•°æ®æ‘˜è¦è¿‡é•¿å·²æˆªæ–­: original_len=%s max_len=%s",
                len("\n".join(lines)),
                _STATS_DATA_SUMMARY_MAX_CHARS,
            )
        return summary_text

    def _build_stats_summary_text(self, summary: dict[str, Any]) -> str:
        return f"""ğŸ“ˆ æ‘˜è¦æ±‡æ€»:
â€¢ æ€»è°ƒç”¨æ¬¡æ•°: {summary["total_calls"]}
â€¢ æ€»æ¶ˆè€— Tokens: {summary["total_tokens"]:,}
  â””â”€ è¾“å…¥: {summary["prompt_tokens"]:,}
  â””â”€ è¾“å‡º: {summary["completion_tokens"]:,}
â€¢ å¹³å‡è€—æ—¶: {summary["avg_duration"]:.2f}s
â€¢ æ¶‰åŠæ¨¡å‹æ•°: {len(summary["models"])}"""

    def set_stats_analysis_result(
        self, group_id: int, request_id: str, analysis: str
    ) -> None:
        """è®¾ç½® AI åˆ†æç»“æœï¼ˆç”±é˜Ÿåˆ—å¤„ç†å™¨è°ƒç”¨ï¼‰"""
        event = self._stats_analysis_events.get(request_id)
        if not event:
            logger.warning(
                "[StatsAnalysis] æœªæ‰¾åˆ°ç­‰å¾…äº‹ä»¶ï¼Œç¾¤: %s, è¯·æ±‚: %s",
                group_id,
                request_id,
            )
            return
        self._stats_analysis_results[request_id] = analysis
        event.set()

    def _build_stats_forward_nodes(
        self,
        summary: dict[str, Any],
        img_dir: Path,
        days: int,
        ai_analysis: str = "",
    ) -> list[dict[str, Any]]:
        """æ„å»ºç”¨äºåˆå¹¶è½¬å‘çš„ç»Ÿè®¡å›¾è¡¨èŠ‚ç‚¹åˆ—è¡¨"""
        nodes = []
        bot_qq = str(self.config.bot_qq)

        # è¾…åŠ©å‡½æ•°ï¼šåˆ›å»ºæ¶ˆæ¯èŠ‚ç‚¹
        def add_node(content: str) -> None:
            nodes.append(
                {
                    "type": "node",
                    "data": {"name": "Bot", "uin": bot_qq, "content": content},
                }
            )

        add_node(f"ğŸ“Š æœ€è¿‘ {days} å¤©çš„ Token ä½¿ç”¨ç»Ÿè®¡ï¼š")

        # æ·»åŠ æ‰€æœ‰ç”Ÿæˆçš„å›¾ç‰‡
        for img_name in ["line_chart", "bar_chart", "pie_chart", "table"]:
            img_path = img_dir / f"stats_{img_name}.png"
            if img_path.exists():
                add_node(f"[CQ:image,file={img_path.absolute().as_uri()}]")

        # æ·»åŠ æ–‡æœ¬æ‘˜è¦
        add_node(self._build_stats_summary_text(summary))

        # æ·»åŠ  AI åˆ†æç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
        if ai_analysis:
            add_node(f"ğŸ¤– AI æ™ºèƒ½åˆ†æ\n{ai_analysis}")

        return nodes

    async def _generate_line_chart(
        self, summary: dict[str, Any], img_dir: Path, days: int
    ) -> None:
        """ç”ŸæˆæŠ˜çº¿å›¾ï¼šæ—¶é—´è¶‹åŠ¿"""
        daily_stats = summary["daily_stats"]
        if not daily_stats:
            return

        # å‡†å¤‡æ•°æ®
        dates = sorted(daily_stats.keys())
        tokens = [daily_stats[d]["tokens"] for d in dates]
        prompt_tokens = [daily_stats[d]["prompt_tokens"] for d in dates]
        completion_tokens = [daily_stats[d]["completion_tokens"] for d in dates]

        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(12, 7))

        # ç»˜åˆ¶æŠ˜çº¿
        ax.plot(
            dates, tokens, marker="o", linewidth=2, label="Total Token", color="#2196F3"
        )
        ax.plot(
            dates,
            prompt_tokens,
            marker="s",
            linewidth=2,
            label="Input Token",
            color="#4CAF50",
        )
        ax.plot(
            dates,
            completion_tokens,
            marker="^",
            linewidth=2,
            label="Output Token",
            color="#FF9800",
        )

        # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
        ax.set_title(
            f"Token Usage Trend for Last {days} Days", fontsize=16, fontweight="bold"
        )
        ax.set_xlabel("Date", fontsize=12)
        ax.set_ylabel("Token Count", fontsize=12)
        ax.legend(loc="upper left", fontsize=10)
        ax.grid(True, alpha=0.3)

        # æ—‹è½¬ x è½´æ ‡ç­¾
        plt.xticks(rotation=45, ha="right")

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        filepath = img_dir / "stats_line_chart.png"
        plt.savefig(filepath, dpi=150, bbox_inches="tight")
        plt.close(fig)

    async def _generate_bar_chart(self, summary: dict[str, Any], img_dir: Path) -> None:
        """ç”ŸæˆæŸ±çŠ¶å›¾ï¼šæ¨¡å‹å¯¹æ¯”"""
        models = summary["models"]
        if not models:
            return

        # å‡†å¤‡æ•°æ®
        model_names = list(models.keys())
        tokens = [models[m]["tokens"] for m in model_names]
        prompt_tokens = [models[m]["prompt_tokens"] for m in model_names]
        completion_tokens = [models[m]["completion_tokens"] for m in model_names]

        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(14, 8))

        # è®¾ç½®æŸ±çŠ¶å›¾ä½ç½®
        x = range(len(model_names))
        width = 0.25

        # ç»˜åˆ¶æŸ±çŠ¶å›¾
        bars1 = ax.bar(
            [i - width for i in x],
            tokens,
            width,
            label="Total Token",
            color="#2196F3",
            alpha=0.8,
        )
        bars2 = ax.bar(
            x,
            prompt_tokens,
            width,
            label="Input Token",
            color="#4CAF50",
            alpha=0.8,
        )
        bars3 = ax.bar(
            [i + width for i in x],
            completion_tokens,
            width,
            label="Output Token",
            color="#FF9800",
            alpha=0.8,
        )

        # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
        ax.set_title("Token Usage Comparison by Model", fontsize=16, fontweight="bold")
        ax.set_xlabel("Model", fontsize=12)
        ax.set_ylabel("Token Count", fontsize=12)
        ax.set_xticks(x)
        ax.set_xticklabels(model_names, rotation=45, ha="right")
        ax.legend(loc="upper right", fontsize=10)
        ax.grid(True, alpha=0.3, axis="y")

        # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for bars in [bars1, bars2, bars3]:
            for bar in bars:
                height = bar.get_height()
                if height > 0:
                    ax.text(
                        bar.get_x() + bar.get_width() / 2.0,
                        height,
                        f"{int(height):,}",
                        ha="center",
                        va="bottom",
                        fontsize=8,
                    )

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        filepath = img_dir / "stats_bar_chart.png"
        plt.savefig(filepath, dpi=150, bbox_inches="tight")
        plt.close(fig)

    async def _generate_pie_chart(self, summary: dict[str, Any], img_dir: Path) -> None:
        """ç”Ÿæˆé¥¼å›¾ï¼šè¾“å…¥/è¾“å‡ºæ¯”ä¾‹"""
        prompt_tokens = summary["prompt_tokens"]
        completion_tokens = summary["completion_tokens"]

        if prompt_tokens == 0 and completion_tokens == 0:
            return

        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(12, 8))

        # å‡†å¤‡æ•°æ®
        labels = ["Input Token", "Output Token"]
        sizes = [prompt_tokens, completion_tokens]
        colors = ["#4CAF50", "#FF9800"]
        explode = (0.05, 0.05)  # çªå‡ºæ˜¾ç¤º

        # ç»˜åˆ¶é¥¼å›¾
        wedges, *_ = ax.pie(
            sizes,
            explode=explode,
            labels=labels,
            colors=colors,
            autopct="%1.1f%%",
            startangle=90,
            textprops={"fontsize": 12},
        )

        # è®¾ç½®æ ‡é¢˜
        ax.set_title("Input/Output Token Ratio", fontsize=16, fontweight="bold", pad=20)

        # æ·»åŠ å›¾ä¾‹
        ax.legend(
            wedges,
            [f"{labels[i]}: {sizes[i]:,}" for i in range(len(labels))],
            loc="center left",
            bbox_to_anchor=(1, 0, 0.5, 1),
            fontsize=10,
        )

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        filepath = img_dir / "stats_pie_chart.png"
        plt.savefig(filepath, dpi=150, bbox_inches="tight")
        plt.close(fig)

    async def _generate_stats_table(
        self, summary: dict[str, Any], img_dir: Path
    ) -> None:
        """ç”Ÿæˆç»Ÿè®¡è¡¨æ ¼"""
        models = summary["models"]
        if not models:
            return

        # å‡†å¤‡æ•°æ®
        model_names = list(models.keys())
        data = []
        for model in model_names:
            m = models[model]
            data.append(
                [
                    model,
                    m["calls"],
                    f"{m['tokens']:,}",
                    f"{m['prompt_tokens']:,}",
                    f"{m['completion_tokens']:,}",
                ]
            )

        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(14, 9))
        ax.axis("tight")
        ax.axis("off")

        # åˆ›å»ºè¡¨æ ¼
        table = ax.table(
            cellText=data,
            colLabels=["Model", "Calls", "Total Token", "Input Token", "Output Token"],
            cellLoc="center",
            loc="center",
        )

        # è®¾ç½®è¡¨æ ¼æ ·å¼
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1.2, 1.5)

        # è®¾ç½®è¡¨å¤´æ ·å¼
        for i in range(5):
            table[(0, i)].set_facecolor("#2196F3")
            table[(0, i)].set_text_props(weight="bold", color="white")

        # è®¾ç½®è¡Œæ ·å¼
        for i in range(1, len(data) + 1):
            for j in range(5):
                if i % 2 == 0:
                    table[(i, j)].set_facecolor("#f0f0f0")

        # è®¾ç½®æ ‡é¢˜
        ax.set_title(
            "Model Usage Statistics Details", fontsize=16, fontweight="bold", pad=20
        )

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        filepath = img_dir / "stats_table.png"
        plt.savefig(filepath, dpi=150, bbox_inches="tight")
        plt.close(fig)

    async def dispatch(
        self, group_id: int, sender_id: int, command: dict[str, Any]
    ) -> None:
        await self._dispatch_internal(
            scope="group",
            group_id=group_id,
            sender_id=sender_id,
            command=command,
            user_id=None,
            send_private_callback=None,
        )

    async def dispatch_private(
        self,
        user_id: int,
        sender_id: int,
        command: dict[str, Any],
        send_private_callback: Callable[[int, str], Awaitable[None]] | None = None,
        is_webui_session: bool = False,
    ) -> None:
        await self._dispatch_internal(
            scope="private",
            group_id=0,
            sender_id=sender_id,
            command=command,
            user_id=user_id,
            send_private_callback=send_private_callback,
            is_webui_session=is_webui_session,
        )

    async def _dispatch_internal(
        self,
        *,
        scope: str,
        group_id: int,
        sender_id: int,
        command: dict[str, Any],
        user_id: int | None,
        send_private_callback: Callable[[int, str], Awaitable[None]] | None,
        is_webui_session: bool = False,
    ) -> None:
        """ç»Ÿä¸€åˆ†å‘å…¥å£ï¼šæ”¯æŒç¾¤èŠä¸ç§èŠã€‚"""
        start_time = time.perf_counter()
        cmd_name = str(command["name"])
        cmd_args = command["args"]

        if scope == "private":
            logger.debug(
                "[å‘½ä»¤] åˆ†å‘è¯·æ±‚: private user=%s sender=%s cmd=%s args_count=%s",
                user_id,
                sender_id,
                cmd_name,
                len(cmd_args),
            )
            target_log = f"private={user_id}"
        else:
            logger.debug(
                "[å‘½ä»¤] åˆ†å‘è¯·æ±‚: group=%s sender=%s cmd=%s args_count=%s",
                group_id,
                sender_id,
                cmd_name,
                len(cmd_args),
            )
            target_log = f"group={group_id}"

        async def _send_target_message(message: str) -> None:
            if scope == "private":
                if user_id is None:
                    logger.warning("[å‘½ä»¤] ç§èŠå‘½ä»¤æ— æ³•å‘é€ï¼šuser_id ä¸º None")
                    return
                target_user_id = int(user_id)
                if send_private_callback is not None:
                    await send_private_callback(target_user_id, message)
                else:
                    await self.sender.send_private_message(target_user_id, message)
            else:
                await self.sender.send_group_message(group_id, message)

        logger.info(
            "[å‘½ä»¤] æ‰§è¡Œå‘½ä»¤: /%s | å‚æ•°=%s | %s", cmd_name, cmd_args, target_log
        )

        self.command_registry.maybe_reload()
        meta = self.command_registry.resolve(cmd_name)
        if meta is None:
            logger.info("[å‘½ä»¤] æœªçŸ¥å‘½ä»¤: /%s", cmd_name)
            await _send_target_message(
                f"âŒ æœªçŸ¥å‘½ä»¤: {cmd_name}\nä½¿ç”¨ /help æŸ¥çœ‹å¯ç”¨å‘½ä»¤"
            )
            return

        if scope == "private" and not meta.allow_in_private:
            logger.info(
                "[å‘½ä»¤] ç§èŠä½œç”¨åŸŸç¦ç”¨: /%s user=%s",
                meta.name,
                user_id,
            )
            await _send_target_message(
                f"âš ï¸ /{meta.name} å½“å‰ä¸æ”¯æŒç§èŠä½¿ç”¨ã€‚è¯·åœ¨ç¾¤èŠä¸­ @æœºå™¨äºº åæ‰§è¡Œã€‚"
            )
            return

        logger.info(
            "[å‘½ä»¤] å‘½ä»¤åŒ¹é…æˆåŠŸ: input=/%s resolved=/%s permission=%s rate_limit=%s private=%s",
            cmd_name,
            meta.name,
            meta.permission,
            meta.rate_limit,
            meta.allow_in_private,
        )

        if cmd_args and cmd_args[0] == "--help":
            await _send_target_message(
                f"âš ï¸ å‚æ•° --help å·²å¼ƒç”¨\nè¯·ä½¿ç”¨ï¼š/help {meta.name}"
            )
            return

        allowed, role_name = self._check_command_permission(meta, sender_id)
        if not allowed:
            logger.warning(
                "[å‘½ä»¤] æƒé™æ ¡éªŒå¤±è´¥: cmd=/%s sender=%s required=%s",
                meta.name,
                sender_id,
                role_name,
            )
            await self._send_no_permission(
                sender_id=sender_id,
                cmd_name=meta.name,
                required_role=role_name,
                send_message=_send_target_message,
            )
            return

        logger.debug("[å‘½ä»¤] æƒé™æ ¡éªŒé€šè¿‡: cmd=/%s sender=%s", meta.name, sender_id)

        if not await self._check_command_rate_limit(
            command_meta=meta,
            sender_id=sender_id,
            send_message=_send_target_message,
        ):
            logger.warning(
                "[å‘½ä»¤] é€Ÿç‡é™åˆ¶æ‹¦æˆª: cmd=/%s scope=%s sender=%s",
                meta.name,
                scope,
                sender_id,
            )
            return

        logger.debug("[å‘½ä»¤] é€Ÿç‡é™åˆ¶é€šè¿‡: cmd=/%s sender=%s", meta.name, sender_id)

        command_sender: Any
        if scope == "private":
            command_sender = _PrivateCommandSenderProxy(
                int(user_id or 0),
                send_private_callback
                or (lambda uid, msg: self.sender.send_private_message(uid, msg)),
            )
        else:
            command_sender = self.sender

        context = CommandContext(
            group_id=group_id,
            sender_id=sender_id,
            config=self.config,
            sender=command_sender,
            ai=self.ai,
            faq_storage=self.faq_storage,
            onebot=self.onebot,
            security=self.security,
            queue_manager=self.queue_manager,
            rate_limiter=self.rate_limiter,
            dispatcher=self,
            registry=self.command_registry,
            scope=scope,
            user_id=user_id,
            is_webui_session=is_webui_session,
        )

        try:
            await self.command_registry.execute(meta, cmd_args, context)
            duration = time.perf_counter() - start_time
            logger.info("[å‘½ä»¤] åˆ†å‘å®Œæˆ: cmd=/%s duration=%.3fs", meta.name, duration)
        except Exception as e:
            duration = time.perf_counter() - start_time
            error_id = uuid4().hex[:8]
            logger.exception(
                "[å‘½ä»¤] æ‰§è¡Œå¤±è´¥: cmd=/%s error_id=%s err=%s",
                meta.name,
                error_id,
                e,
            )
            logger.error(
                "[å‘½ä»¤] åˆ†å‘å¤±è´¥: cmd=/%s duration=%.3fs error_id=%s",
                meta.name,
                duration,
                error_id,
            )
            await _send_target_message(
                f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ï¼ˆé”™è¯¯ç : {error_id}ï¼‰"
            )

    def _check_command_permission(
        self,
        command_meta: CommandMeta,
        sender_id: int,
    ) -> tuple[bool, str]:
        permission = command_meta.permission
        if permission == "superadmin":
            return self.config.is_superadmin(sender_id), "è¶…çº§ç®¡ç†å‘˜"
        if permission == "admin":
            return self.config.is_admin(sender_id), "ç®¡ç†å‘˜"
        return True, ""

    async def _check_command_rate_limit(
        self,
        command_meta: CommandMeta,
        sender_id: int,
        send_message: Callable[[str], Awaitable[None]],
    ) -> bool:
        rate_limit = command_meta.rate_limit

        # è·å– rate_limiter å®ä¾‹
        limiter = self.rate_limiter
        if limiter is None and hasattr(self.security, "rate_limiter"):
            limiter = self.security.rate_limiter

        if limiter is None:
            logger.warning(
                "[å‘½ä»¤] é™æµå™¨ç¼ºå¤±ï¼Œè·³è¿‡é™æµ: cmd=/%s",
                command_meta.name,
            )
            return True

        allowed, remaining = limiter.check_command(
            sender_id, command_meta.name, rate_limit
        )
        if not allowed:
            if remaining >= 60:
                minutes = remaining // 60
                seconds = remaining % 60
                time_str = f"{minutes}åˆ†{seconds}ç§’" if minutes > 0 else f"{seconds}ç§’"
            else:
                time_str = f"{remaining}ç§’"

            await send_message(
                f"â³ /{command_meta.name} å‘½ä»¤å¤ªé¢‘ç¹ï¼Œè¯· {time_str}åå†è¯•"
            )
            return False

        limiter.record_command(sender_id, command_meta.name, rate_limit)
        logger.debug(
            "[å‘½ä»¤] åŠ¨æ€é™æµè®°å½•æˆåŠŸ: cmd=/%s sender=%s limits=%s",
            command_meta.name,
            sender_id,
            f"U:{rate_limit.user}/A:{rate_limit.admin}",
        )
        return True

    async def _send_no_permission(
        self,
        sender_id: int,
        cmd_name: str,
        required_role: str,
        send_message: Callable[[str], Awaitable[None]],
    ) -> None:
        logger.warning("[å‘½ä»¤] æƒé™ä¸è¶³: sender=%s cmd=/%s", sender_id, cmd_name)
        await send_message(f"âš ï¸ æƒé™ä¸è¶³ï¼šåªæœ‰{required_role}å¯ä»¥ä½¿ç”¨æ­¤å‘½ä»¤")

    async def _handle_bugfix(
        self, group_id: int, admin_id: int, args: list[str]
    ) -> None:
        """å¤„ç† /bugfix å‘½ä»¤ï¼Œé€šè¿‡åˆ†æèŠå¤©è®°å½•è‡ªåŠ¨ç”Ÿæˆ FAQ å½’æ¡£"""
        # 1. å‚æ•°è§£æ
        parsed = self._parse_bugfix_args(args)
        if isinstance(parsed, str):
            await self.sender.send_group_message(group_id, parsed)
            return

        target_qqs, start_date, end_date, start_str, end_str = parsed

        await self.sender.send_group_message(
            group_id, "ğŸ” æ­£åœ¨è·å–å¯¹è¯è®°å½•è¿›è¡Œå›æº¯åˆ†æ..."
        )

        try:
            # 2. è·å–å¹¶å¤„ç†æ¶ˆæ¯
            messages = await self._fetch_messages(
                group_id, target_qqs, start_date, end_date
            )
            if not messages:
                await self.sender.send_group_message(
                    group_id, "âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¯¹è¯è®°å½•ã€‚"
                )
                return

            processed_text = await self._process_messages(messages)

            # 3. ç”Ÿæˆæ‘˜è¦æ€»ç»“
            summary = await self._obtain_bugfix_summary(group_id, processed_text)

            # 4. ç”Ÿæˆæ ‡é¢˜å¹¶å…¥åº“
            title = extract_faq_title(summary)
            if not title or title == "æœªå‘½åé—®é¢˜":
                title = await self.ai.generate_title(summary)

            faq = await self.faq_storage.create(
                group_id=group_id,
                target_qq=target_qqs[0],
                start_time=start_str,
                end_time=end_str,
                title=title,
                content=summary,
            )

            result_msg = f"âœ… Bug ä¿®å¤åˆ†æå®Œæˆï¼\n\nğŸ“Œ FAQ ID: {faq.id}\nğŸ“‹ æ ‡é¢˜: {title}\n\n{summary}"
            await self.sender.send_group_message(group_id, result_msg)

        except Exception as e:
            error_id = uuid4().hex[:8]
            logger.exception("Bugfix å¤±è´¥: error_id=%s err=%s", error_id, e)
            await self.sender.send_group_message(
                group_id,
                f"âŒ Bug ä¿®å¤åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ï¼ˆé”™è¯¯ç : {error_id}ï¼‰",
            )

    def _parse_bugfix_args(
        self, args: list[str]
    ) -> tuple[list[int], datetime, datetime, str, str] | str:
        """è§£æ bugfix å‘½ä»¤çš„å‚æ•°"""
        if len(args) < 3:
            return (
                "âŒ ç”¨æ³•: /bugfix <QQå·1> [QQå·2] ... <å¼€å§‹æ—¶é—´> <ç»“æŸæ—¶é—´>\n"
                "æ—¶é—´æ ¼å¼: YYYY/MM/DD/HH:MMï¼Œç»“æŸæ—¶é—´å¯ç”¨ now\n"
                "ç¤ºä¾‹: /bugfix 123456 2024/12/01/09:00 now"
            )

        try:
            target_qqs = [int(arg) for arg in args[:-2]]
            start_str, end_str_raw = args[-2], args[-1]
            start_date = datetime.strptime(start_str, "%Y/%m/%d/%H:%M")

            if end_str_raw.lower() == "now":
                end_date, end_str = datetime.now(), "now"
            else:
                end_date, end_str = (
                    datetime.strptime(end_str_raw, "%Y/%m/%d/%H:%M"),
                    end_str_raw,
                )

            return target_qqs, start_date, end_date, start_str, end_str
        except ValueError:
            return "âŒ å‚æ•°æ ¼å¼é”™è¯¯ï¼šQQå·åº”ä¸ºæ•°å­—ï¼Œæ—¶é—´æ ¼å¼åº”ä¸º YYYY/MM/DD/HH:MMã€‚"

    async def _obtain_bugfix_summary(self, group_id: int, processed_text: str) -> str:
        """åˆ©ç”¨ AI ç”ŸæˆèŠå¤©è®°å½•çš„ Bug åˆ†ææ‘˜è¦"""
        total_tokens = self.ai.count_tokens(processed_text)
        max_tokens = self.config.chat_model.max_tokens

        if total_tokens <= max_tokens:
            return str(await self.ai.summarize_chat(processed_text))

        await self.sender.send_group_message(
            group_id, f"ğŸ“Š æ¶ˆæ¯è¾ƒé•¿ï¼ˆ{total_tokens} tokensï¼‰ï¼Œæ­£åœ¨åˆ†æ®µå¤„ç†..."
        )
        chunks = self.ai.split_messages_by_tokens(processed_text, max_tokens)
        summaries = [await self.ai.summarize_chat(chunk) for chunk in chunks]
        return str(await self.ai.merge_summaries(summaries))

    async def _fetch_messages(
        self,
        group_id: int,
        target_qqs: list[int],
        start_date: datetime,
        end_date: datetime,
    ) -> list[dict[str, Any]]:
        batch = await self.onebot.get_group_msg_history(group_id, count=2500)
        if not batch:
            return []
        target_qqs_set = set(target_qqs)
        results = []
        for msg in batch:
            msg_time = parse_message_time(msg)
            if (
                start_date <= msg_time <= end_date
                and get_message_sender_id(msg) in target_qqs_set
            ):
                results.append(msg)
        return sorted(results, key=lambda m: m.get("time", 0))

    async def _process_messages(self, messages: list[dict[str, Any]]) -> str:
        lines = []
        for msg in messages:
            sender_id = get_message_sender_id(msg)
            msg_time = parse_message_time(msg).strftime("%Y-%m-%d %H:%M:%S")
            content = get_message_content(msg)
            text_parts = []
            for segment in content:
                seg_type, seg_data = segment.get("type", ""), segment.get("data", {})
                if seg_type == "text":
                    text_parts.append(seg_data.get("text", ""))
                elif seg_type == "image":
                    file = seg_data.get("file", "") or seg_data.get("url", "")
                    if file:
                        try:
                            url = await self.onebot.get_image(file)
                            if url:
                                res = await self.ai.analyze_multimodal(url, "image")
                                text_parts.append(
                                    f"[pic]<desc>{res.get('description', '')}</desc><text>{res.get('ocr_text', '')}</text>[/pic]"
                                )
                        except Exception:
                            text_parts.append("[pic]<desc>å›¾ç‰‡å¤„ç†å¤±è´¥</desc>[/pic]")
                elif seg_type == "at":
                    text_parts.append(f"@{seg_data.get('qq', '')}")
            if text_parts:
                lines.append(f"[{msg_time}] {sender_id}: {''.join(text_parts)}")
        return "\n".join(lines)
